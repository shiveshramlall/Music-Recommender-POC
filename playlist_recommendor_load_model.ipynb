{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All imports needed for notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle as pk\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# -- local files\n",
    "from modules import spotify_methods as sm\n",
    "from modules import content_recommender as cr\n",
    "from modules import recommender_methods as rm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Load Model and Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = rm.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.getcwd() + \"\\\\model\" + \"\\\\training_data.pkl\"\n",
    "\n",
    "with open(filename, 'rb') as fp:\n",
    "    training_data = pk.load(fp)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Select a playlist and no of recommendations (max 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_pid = 100000\n",
    "required_recommendations = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, all_rec_songs = loaded([str(select_pid)])\n",
    "print(f\"Recommendations subset: {all_rec_songs[0][:10]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Remove songs that are already in the playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_playlist = rm.show_playlist(select_pid, training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_recommendations = rm.decode_and_select(all_rec_songs, required_recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_duped_rec = rm.remove_known_positives(selected_recommendations, orig_playlist)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Use a Content Based Recommendor to sort through recommendation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_songs = pd.read_csv('./song_features.csv')\n",
    "to_cache_items=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr_features = []\n",
    "for sr in de_duped_rec:\n",
    "\n",
    "    search_result, to_cache = sm.get_song_data(sr, cached_songs)\n",
    "    if(search_result is not None):\n",
    "        sr_features += [search_result]\n",
    "    if(search_result is None):\n",
    "        print(f'''Not found: {sr}''')\n",
    "    if(to_cache):\n",
    "        to_cache_items += [search_result]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_features = []\n",
    "for op in orig_playlist:\n",
    "    \n",
    "    search_result, to_cache = sm.get_song_data(op, cached_songs)\n",
    "    if(search_result is not None):\n",
    "        op_features += [search_result]\n",
    "    if(search_result is None):\n",
    "        print(f'''Not found: {op}''')\n",
    "    if(to_cache):\n",
    "        to_cache_items += [search_result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cached_songs = pd.DataFrame(to_cache_items)\n",
    "combine_frames = [cached_songs, new_cached_songs]\n",
    "\n",
    "all_cached_songs = pd.concat(combine_frames)\n",
    "all_cached_songs.to_csv(path_or_buf=\"song_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_cluster_pipeline, number_cols = cr.cluster_pipeline(sr_features, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr.recommend_songs(op_features, sr_features, song_cluster_pipeline, number_cols)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ae0582920bd24d03b21545c5279ef39598b67f1ebcb1fd7a047e45a89e1b0f1b"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('tf-gpu-2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
